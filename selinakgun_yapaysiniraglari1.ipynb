{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcPm+T7SVdJicumhL/7HtT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/selinakgun/-/blob/master/selinakgun_yapaysiniraglari1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Veri Setinin YÃ¼klenmesi**"
      ],
      "metadata": {
        "id": "9WSkIKb9mqSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Veri Seti SeÃ§imi ve GerekÃ§esi:** *Breast Cancer Wisconsin (Diagnostic)*\n",
        "\n",
        "Bu Ã§alÄ±ÅŸma iÃ§in Scikit-learn kÃ¼tÃ¼phanesinde yer alan Breast Cancer Wisconsin veri seti tercih edilmiÅŸtir. Bu seÃ§imin temel nedenleri ÅŸunlardÄ±r:\n",
        "\n",
        "Problemin DoÄŸasÄ± (Ä°kili SÄ±nÄ±flandÄ±rma): Ã–dev kapsamÄ±nda istenen ROC EÄŸrisi analizleri, ikili sÄ±nÄ±flandÄ±rma (binary classification) problemlerinde en net ve yorumlanabilir sonuÃ§larÄ± vermektedir. Hedef deÄŸiÅŸkenin \"Ä°yi Huylu (Benign)\" ve \"KÃ¶tÃ¼ Huylu (Malignant)\" olmak Ã¼zere iki sÄ±nÄ±ftan oluÅŸmasÄ±, model performansÄ±nÄ±n hassasiyet (sensitivity) ve Ã¶zgÃ¼llÃ¼k (specificity) baÄŸlamÄ±nda deÄŸerlendirilmesini kolaylaÅŸtÄ±rÄ±r.\n",
        "\n",
        "XAI (AÃ§Ä±klanabilir Yapay Zeka) UygunluÄŸu: Veri setindeki Ã¶znitelikler (yarÄ±Ã§ap, doku, Ã§evre, alan vb.) fiziksel ve tÄ±bbi karÅŸÄ±lÄ±ÄŸÄ± olan gerÃ§ek deÄŸerlerdir. Bu durum, Ã¶devin ilerleyen aÅŸamalarÄ±nda uygulanacak XAI yÃ¶ntemleri ile modelin karar mekanizmasÄ±nÄ±n aÃ§Ä±klanmasÄ±nÄ± (Ã¶rneÄŸin; \"yarÄ±Ã§ap arttÄ±kÃ§a risk artÄ±yor\" gibi) anlamlÄ± kÄ±lar.\n",
        "\n",
        "Veri Hacmi ve Boyutu: Veri seti 569 Ã¶rneklem ve 30 Ã¶znitelikten oluÅŸmaktadÄ±r. Bu boyut, Ã¶devde istenen hiperparametre optimizasyonu ve tekrarlÄ± eÄŸitim (20 kez shuffle) sÃ¼reÃ§lerinin makul sÃ¼relerde tamamlanmasÄ±na olanak tanÄ±rken, yapay sinir aÄŸÄ±nÄ±n (YSA) Ã¶ÄŸrenmesi iÃ§in de yeterli veri yoÄŸunluÄŸunu saÄŸlar."
      ],
      "metadata": {
        "id": "W4iXq1QDRNat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1.1 scikit-learnâ€™den Veri Seti YÃ¼kleme (Breast Cancer)\n",
        "# ---------------------------------------------------------\n",
        "data = load_breast_cancer()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1.2 Veri Ã‡erÃ§evesi OluÅŸturma ve X, y AyrÄ±mÄ±\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Ã–zellikler (X) ve Hedef (y) deÄŸiÅŸkenlerinin ayrÄ±lmasÄ±\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Verinin daha rahat incelenebilmesi iÃ§in pandas DataFrame formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmesi\n",
        "# SÃ¼tun isimlerini veri setinin kendi tanÄ±mlarÄ±ndan alÄ±yoruz\n",
        "df = pd.DataFrame(X, columns=data.feature_names)\n",
        "\n",
        "# Hedef deÄŸiÅŸkeni de (target) gÃ¶rsel kontrol iÃ§in DataFrame'e ekleyelim\n",
        "# (Not: EÄŸitimde X ve y ayrÄ± kullanÄ±lacak ama tablo olarak gÃ¶rmek iÃ§in ekliyoruz)\n",
        "df['target'] = y\n",
        "\n",
        "# Ä°lk 5 satÄ±rÄ±n gÃ¶rÃ¼ntÃ¼lenmesi\n",
        "print(\"Veri Setinin Ä°lk 5 SatÄ±rÄ±:\")\n",
        "print(df.head())\n",
        "\n",
        "# Veri setinin boyutlarÄ±nÄ± kontrol (Rapora yazmak iÃ§in bilgi)\n",
        "print(f\"\\nVeri Seti Boyutu: {df.shape}\")"
      ],
      "metadata": {
        "id": "58XBpa89SXyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Veri Setinin YÃ¼klenmesi**\n",
        "Bu Ã§alÄ±ÅŸmada, ikili sÄ±nÄ±flandÄ±rma (binary classification) problemi iÃ§in literatÃ¼rde yaygÄ±n olarak kullanÄ±lan ve Scikit-learn kÃ¼tÃ¼phanesinde yer alan Breast Cancer Wisconsin (Diagnostic) veri seti seÃ§ilmiÅŸtir.\n",
        "\n",
        "Kod bloÄŸunda gerÃ§ekleÅŸtirilen iÅŸlemler sÄ±rasÄ±yla ÅŸÃ¶yledir:\n",
        "\n",
        "Veri seti kÃ¼tÃ¼phaneden Ã§aÄŸrÄ±lmÄ±ÅŸ, baÄŸÄ±msÄ±z deÄŸiÅŸkenler (Ã¶znitelikler) X matrisine, baÄŸÄ±mlÄ± deÄŸiÅŸken (hedef sÄ±nÄ±f - Ä°yi/KÃ¶tÃ¼ Huylu) y vektÃ¶rÃ¼ne atanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Veri yapÄ±sÄ±nÄ±n analizi ve gÃ¶rselleÅŸtirilmesinin kolaylaÅŸmasÄ± amacÄ±yla ham veri, Pandas DataFrame formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "head() fonksiyonu ile alÄ±nan ilk 5 satÄ±r incelendiÄŸinde, veri setinin sayÄ±sal Ã¶zniteliklerden (radius, texture, perimeter vb.) oluÅŸtuÄŸu gÃ¶zlemlenmiÅŸtir. Veri seti toplam 569 Ã¶rneklem, 30 Ã¶znitelik ve 1 hedef deÄŸiÅŸken oluÅŸmaktadÄ±r."
      ],
      "metadata": {
        "id": "7d3YXsUyUo7n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. AdÄ±m: Veri Seti Kalite Kontrolleri**"
      ],
      "metadata": {
        "id": "uiSj4wUtX9zI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **BÃ¶lÃ¼m 2.1: Eksik DeÄŸer Analizi**"
      ],
      "metadata": {
        "id": "suo3NiLZZmJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 2. Veri Seti Kalite Kontrolleri\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 2.1 Eksik DeÄŸer Analizi\n",
        "\n",
        "# Her sÃ¼tundaki eksik deÄŸer (NaN/Null) sayÄ±sÄ±nÄ± kontrol edelim\n",
        "eksik_degerler = df.isnull().sum()\n",
        "\n",
        "print(\"SÃ¼tun bazlÄ± eksik deÄŸer sayÄ±larÄ±:\")\n",
        "print(eksik_degerler)\n",
        "\n",
        "# Toplam eksik veri kontrolÃ¼\n",
        "toplam_eksik = eksik_degerler.sum()\n",
        "\n",
        "if toplam_eksik > 0:\n",
        "    print(f\"\\nToplam {toplam_eksik} adet eksik veri bulundu.\")\n",
        "    # EÄŸer eksik veri olsaydÄ±, ortalama ile dolduracak (Imputation)\n",
        "    from sklearn.impute import SimpleImputer\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    X = imputer.fit_transform(X)\n",
        "    print(\"Eksik veriler sÃ¼tun ortalamalarÄ±yla dolduruldu.\")\n",
        "else:\n",
        "    print(\"\\nVeri setinde eksik deÄŸer (missing value) bulunmamaktadÄ±r. Dolgu iÅŸlemine gerek duyulmamÄ±ÅŸtÄ±r.\")"
      ],
      "metadata": {
        "id": "EUi2xSELX_LF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÃ¶lÃ¼m 2.1: Eksik DeÄŸer Analizi Veri setinin kalitesini Ã¶lÃ§mek amacÄ±yla isnull().sum() fonksiyonu kullanÄ±larak her bir sÃ¼tun iÃ§in ayrÄ± ayrÄ± kayÄ±p veri (missing value) taramasÄ± yapÄ±lmÄ±ÅŸtÄ±r. YapÄ±lan analiz sonucunda veri setindeki hiÃ§bir Ã¶znitelikte eksik deÄŸere rastlanmamÄ±ÅŸtÄ±r. Bu nedenle herhangi bir veri doldurma (imputation) iÅŸlemi uygulanmasÄ±na gerek kalmamÄ±ÅŸtÄ±r. Veri seti eksiksiz ve analize hazÄ±rdÄ±r."
      ],
      "metadata": {
        "id": "bFWYvdO_YQ5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BÃ¶lÃ¼m 2.2: AykÄ±rÄ± DeÄŸer Analizi (Boxplot)**"
      ],
      "metadata": {
        "id": "MpAF4zRFZjAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2.2 AykÄ±rÄ± DeÄŸer (Outlier) Analizi - TÃœM Ã–ZELLÄ°KLER Ä°Ã‡Ä°N BOXPLOT\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Ã–zellik isimlerini alalÄ±m (sondaki 'target' sÃ¼tununu hariÃ§ tutuyoruz)\n",
        "features = df.columns[:-1]\n",
        "num_features = len(features)\n",
        "\n",
        "# KaÃ§ satÄ±r ve sÃ¼tunluk bir Ä±zgara (grid) lazÄ±m hesaplayalÄ±m\n",
        "# 30 Ã¶zellik iÃ§in 6 satÄ±r x 5 sÃ¼tun gÃ¼zel durur.\n",
        "num_rows = math.ceil(num_features / 5)\n",
        "num_cols = 5\n",
        "\n",
        "# Ã‡izim alanÄ±nÄ± hazÄ±rlayalÄ±m (BoyutlarÄ± biraz bÃ¼yÃ¼k tutuyoruz ki sÄ±ÄŸsÄ±n)\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 25))\n",
        "axes = axes.flatten() # DÃ¶ngÃ¼de rahat gezmek iÃ§in dÃ¼zleÅŸtiriyoruz\n",
        "\n",
        "# Her Ã¶zellik iÃ§in dÃ¶ngÃ¼\n",
        "for i, col in enumerate(features):\n",
        "    sns.boxplot(y=df[col], ax=axes[i], color='skyblue')\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "    axes[i].set_ylabel(\"\") # Y ekseni etiketini kalabalÄ±k yapmasÄ±n diye siliyoruz\n",
        "\n",
        "# BoÅŸ kalan Ã§erÃ§eveleri (eÄŸer varsa) gizleyelim\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.suptitle(\"TÃ¼m Ã–zniteliklerin AykÄ±rÄ± DeÄŸer Analizi (Boxplot)\", fontsize=16, y=1.02)\n",
        "plt.tight_layout() # Grafikler birbirine girmesin diye aralarÄ± aÃ§\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ha4ghjFXZY-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Grafikler incelendiÄŸinde, Ã¶zellikle 'area error', 'worst area' gibi alan ve Ã¶lÃ§Ã¼ belirten Ã¶zniteliklerde Ã¼st sÄ±nÄ±rÄ±n (bÄ±yÄ±k) Ã¼zerinde kalan Ã§ok sayÄ±da nokta (outlier) gÃ¶zlemlenmiÅŸtir. TÄ±bbi veri setlerinde, ortalamadan bu denli sapan yÃ¼ksek deÄŸerler genellikle patolojik bir durumu (kanserin ciddiyetini) iÅŸaret eden deÄŸerli bilgilerdir. Bu deÄŸerlerin Ã¶lÃ§Ã¼m hatasÄ± deÄŸil, hastalÄ±ÄŸÄ±n doÄŸasÄ± gereÄŸi \"gerÃ§ek uÃ§ deÄŸerler\" olma ihtimali yÃ¼ksektir. Bu nedenle, modelin kanserli hÃ¼creleri tespit yeteneÄŸini kaybetmemek adÄ±na aykÄ±rÄ± deÄŸer silme iÅŸlemi uygulanmamÄ±ÅŸ, verinin doÄŸal yapÄ±sÄ± korunmuÅŸtur."
      ],
      "metadata": {
        "id": "JGed-HnoZ3wH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Ek Analiz: Z-Score ve IQR YÃ¶ntemleri ile SaÄŸlama\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def outlier_kontrol(sutun_adi):\n",
        "    veriler = df[sutun_adi]\n",
        "\n",
        "    # --- 1. Z-Score YÃ¶ntemi ---\n",
        "    # Ortalamadan 3 standart sapma uzaklaÅŸanlar aykÄ±rÄ±dÄ±r.\n",
        "    z_scores = np.abs(stats.zscore(veriler))\n",
        "    z_score_outliers = np.where(z_scores > 3)[0] # SÄ±nÄ±rÄ± geÃ§enlerin indeksleri\n",
        "\n",
        "    # --- 2. IQR (Interquartile Range) YÃ¶ntemi ---\n",
        "    # Veriyi 4 Ã§eyreÄŸe bÃ¶l, ortadaki %50'nin dÄ±ÅŸÄ±na taÅŸanlarÄ± yakala.\n",
        "    Q1 = veriler.quantile(0.25)\n",
        "    Q3 = veriler.quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    alt_sinir = Q1 - 1.5 * IQR\n",
        "    ust_sinir = Q3 + 1.5 * IQR\n",
        "\n",
        "    iqr_outliers = df[(veriler < alt_sinir) | (veriler > ust_sinir)].index\n",
        "\n",
        "    print(f\"--- '{sutun_adi}' Ã–zelliÄŸi Ä°Ã§in Analiz ---\")\n",
        "    print(f\"Z-Score YÃ¶ntemi (EÅŸik=3) ile bulunan aykÄ±rÄ± deÄŸer sayÄ±sÄ±: {len(z_score_outliers)}\")\n",
        "    print(f\"IQR YÃ¶ntemi (1.5x) ile bulunan aykÄ±rÄ± deÄŸer sayÄ±sÄ±: {len(iqr_outliers)}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Ä°ki farklÄ± karakterdeki sÃ¼tun iÃ§in deneyelim\n",
        "outlier_kontrol('mean area')      # YukarÄ± doÄŸru patlayan veri\n",
        "outlier_kontrol('mean symmetry')  # Hem aÅŸaÄŸÄ± hem yukarÄ± taÅŸabilen veri"
      ],
      "metadata": {
        "id": "d4jZw_rCbFH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ek Analiz**\n",
        "GÃ¶rsel olarak Boxplot ile tespit edilen aykÄ±rÄ± deÄŸerler, Z-Score ve IQR (Ã‡eyrekler AÃ§Ä±klÄ±ÄŸÄ±) yÃ¶ntemleriyle de matematiksel olarak test edilmiÅŸtir.\n",
        "\n",
        "Ã–rneÄŸin 'mean area' Ã¶zniteliÄŸi iÃ§in yapÄ±lan analizde; IQR yÃ¶ntemi daha hassas davranarak daha fazla sayÄ±da aykÄ±rÄ± deÄŸer tespit ederken, Z-Score yÃ¶ntemi (EÅŸik=3) sadece en uÃ§taki vakalarÄ± yakalamÄ±ÅŸtÄ±r.\n",
        "\n",
        "Her iki istatistiksel yÃ¶ntem de Boxplot grafiklerini destekler niteliktedir. Bu deÄŸerlerin veri setinden atÄ±lmamasÄ± gerektiÄŸi, farklÄ± yÃ¶ntemlerin de bunlarÄ± \"nadir ama gerÃ§ek\" veriler olarak iÅŸaretlemesiyle doÄŸrulanmÄ±ÅŸtÄ±r."
      ],
      "metadata": {
        "id": "ugQGvfbKbUPy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdÄ±m 2.3: Veri Tipi ve DeÄŸiÅŸken Analizi Kodu**"
      ],
      "metadata": {
        "id": "nbHRv428cDka"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 2.3 Veri Tipi ve DaÄŸÄ±lÄ±m Ä°ncelemesi\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. SÃ¼tunlarÄ±n veri tiplerini (dtype) gÃ¶sterelim\n",
        "print(\"--- SÃ¼tunlarÄ±n Veri Tipleri (Dtypes) ---\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# 2. SayÄ±sal ve Kategorik deÄŸiÅŸkenleri sayalÄ±m\n",
        "# SayÄ±sal olanlarÄ± (int, float) ve SÃ¶zel olanlarÄ± (object) ayÄ±ralÄ±m\n",
        "sayisal_sutunlar = df.select_dtypes(include=['float64', 'int64', 'int32']).columns\n",
        "kategorik_sutunlar = df.select_dtypes(include=['object', 'category']).columns\n",
        "\n",
        "print(\"\\n--- DeÄŸiÅŸken Analizi Raporu ---\")\n",
        "print(f\"Toplam DeÄŸiÅŸken SayÄ±sÄ±: {df.shape[1]}\")\n",
        "print(f\"SayÄ±sal DeÄŸiÅŸken SayÄ±sÄ± (Float/Int): {len(sayisal_sutunlar)}\")\n",
        "print(f\"Kategorik DeÄŸiÅŸken SayÄ±sÄ± (Object): {len(kategorik_sutunlar)}\")\n",
        "\n",
        "# EÄŸer kategorik deÄŸiÅŸken yoksa, bunu belirtelim\n",
        "if len(kategorik_sutunlar) == 0:\n",
        "    print(\"\\nNot: Veri setinde 'Kategorik' (metin/string) tipinde deÄŸiÅŸken bulunmamaktadÄ±r.\")\n",
        "    print(\"TÃ¼m veriler sayÄ±sal formatta olduÄŸu iÃ§in 'Label Encoding' veya 'One-Hot Encoding' iÅŸlemine gerek yoktur.\")"
      ],
      "metadata": {
        "id": "YEwGbu0fbUEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÃ¶lÃ¼m 2.3: Veri Tipi ve DaÄŸÄ±lÄ±m Ä°ncelemesi Veri setindeki Ã¶zniteliklerin yapÄ±sal Ã¶zelliklerini belirlemek amacÄ±yla df.dtypes ve select_dtypes fonksiyonlarÄ± kullanÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Analiz Sonucu:\n",
        "\n",
        "Veri setindeki 31 deÄŸiÅŸkenin tamamÄ± sayÄ±sal (30 adet float64 ve 1 adet int64 - target) veri tipindedir.\n",
        "\n",
        "Veri setinde metin veya sÄ±nÄ±f tabanlÄ± (string/object) kategorik deÄŸiÅŸken bulunmamaktadÄ±r.\n",
        "\n",
        "TÃ¼m Ã¶zniteliklerin halihazÄ±rda sayÄ±sal formatta olmasÄ±, Yapay Sinir AÄŸÄ± (YSA) modellemesi Ã¶ncesinde One-Hot Encoding veya Label Encoding gibi ek dÃ¶nÃ¼ÅŸÃ¼m iÅŸlemlerine ihtiyaÃ§ duyulmadÄ±ÄŸÄ±nÄ± gÃ¶stermektedir. Veri, format aÃ§Ä±sÄ±ndan doÄŸrudan modellemeye uygundur."
      ],
      "metadata": {
        "id": "O-d4O_OmcKbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. KeÅŸifsel Veri Analizi (EDA)"
      ],
      "metadata": {
        "id": "BHaPxVxsfBuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------\n",
        "# 3. KeÅŸifsel Veri Analizi (EDA)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 3.1 Ä°statistiksel Ã–zellikler\n",
        "# Pandas'Ä±n describe() fonksiyonu istenen tÃ¼m deÄŸerleri verir:\n",
        "# mean (Ortalama), std (Standart Sapma), min, max\n",
        "# 25% (Q1), 50% (Medyan), 75% (Q3)\n",
        "\n",
        "istatistik_ozeti = df.describe().T\n",
        "\n",
        "# TÃ¼m sÃ¼tunlarÄ± seÃ§ip gÃ¶sterelim (Count'u Ã§Ä±karabiliriz)\n",
        "print(\"Veri Seti Ä°statistiksel Ã–zeti:\")\n",
        "print(istatistik_ozeti)\n",
        "\n",
        "# Rapora eklemek iÃ§in bu Ã¶zeti bir deÄŸiÅŸkene atadÄ±k,\n"
      ],
      "metadata": {
        "id": "bnccqNFGfa8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÃ¶lÃ¼m 3.1: Ä°statistiksel Ã–zellikler Veri setindeki her bir Ã¶znitelik iÃ§in temel istatistiksel metrikler (Ortalama, Medyan, Standart Sapma, Min-Max ve Ã‡eyrekler) describe() fonksiyonu ile hesaplanmÄ±ÅŸtÄ±r (Bkz. Tablo X).\n",
        "\n",
        "\n",
        "\n",
        "Ã–lÃ§ek FarklÄ±lÄ±klarÄ±: Tablo incelendiÄŸinde Ã¶zniteliklerin Ã¶lÃ§eklerinin birbirinden Ã§ok farklÄ± olduÄŸu gÃ¶rÃ¼lmektedir. Ã–rneÄŸin mean area (Ortalama Alan) 2500'lÃ¼ deÄŸerlere (Max: 2501) ulaÅŸÄ±rken, smoothness error (PÃ¼rÃ¼zsÃ¼zlÃ¼k hatasÄ±) 0.001 seviyelerindedir. Bu durum, Ã¶nceki adÄ±mlarda uygulanan Standardizasyon (Scaling) iÅŸleminin Yapay Sinir AÄŸÄ± baÅŸarÄ±sÄ± iÃ§in ne kadar kritik olduÄŸunu doÄŸrulamaktadÄ±r.\n",
        "\n",
        "DaÄŸÄ±lÄ±m Bilgisi: Mean (Ortalama) ve 50% (Medyan) deÄŸerleri arasÄ±ndaki farklar, verinin Ã§arpÄ±klÄ±ÄŸÄ± (skewness) hakkÄ±nda bilgi vermektedir. Ã–zellikle 'Area' ve 'Concavity' gibi Ã¶zelliklerde ortalamanÄ±n medyandan bÃ¼yÃ¼k olmasÄ±, daÄŸÄ±lÄ±mÄ±n saÄŸa Ã§arpÄ±k (pozitif yÃ¶nlÃ¼ aykÄ±rÄ± deÄŸerler) olduÄŸunu gÃ¶stermektedir."
      ],
      "metadata": {
        "id": "NHmzaiVHhH-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.2 Korelasyon Matrisi**"
      ],
      "metadata": {
        "id": "F5u3RSgwfDkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3.2 Korelasyon Matrisi ve Heatmap\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. Pearson Korelasyon Matrisini Hesapla\n",
        "# corr() fonksiyonu varsayÄ±lan olarak Pearson yÃ¶ntemini kullanÄ±r.\n",
        "corr_matrix = df.corr(method='pearson')\n",
        "\n",
        "# 2. Heatmap ile GÃ¶rselleÅŸtirme\n",
        "# BÃ¼yÃ¼k bir matris olduÄŸu iÃ§in boyutu (figsize) bÃ¼yÃ¼k tutuyoruz.\n",
        "plt.figure(figsize=(20, 18))\n",
        "sns.heatmap(corr_matrix, annot=True, fmt=\".1f\", cmap='coolwarm', linewidths=.5)\n",
        "plt.title(\"Ã–znitelikler ArasÄ± Pearson Korelasyon Matrisi\")\n",
        "plt.show()\n",
        "\n",
        "# 3. En YÃ¼ksek Korelasyonlu 3 Ã‡ifti Bulma ve Yorumlama\n",
        "# Matrisin Ã¼st Ã¼Ã§genini alÄ±yoruz ki (A,B) ve (B,A) diye aynÄ± ÅŸeyi iki kere yazmasÄ±n.\n",
        "maske = np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
        "sirali_korelasyonlar = corr_matrix.where(maske).stack().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\n--- En YÃ¼ksek Korelasyonlu 3 Ã–znitelik Ã‡ifti ---\")\n",
        "print(sirali_korelasyonlar.head(3))"
      ],
      "metadata": {
        "id": "ybNyP93eiiGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BÃ¶lÃ¼m 3.2: Korelasyon Analizi:**\n",
        "Ã–znitelikler arasÄ±ndaki doÄŸrusal iliÅŸkiyi incelemek iÃ§in Pearson korelasyon katsayÄ±sÄ± hesaplanmÄ±ÅŸ ve Heatmap (IsÄ± HaritasÄ±) ile gÃ¶rselleÅŸtirilmiÅŸtir (Bkz. Åekil X). KÄ±rmÄ±zÄ± renkler pozitif yÃ¼ksek iliÅŸkiyi, mavi renkler negatif iliÅŸkiyi temsil etmektedir.\n",
        "En YÃ¼ksek Korelasyonlu 3 Ã‡ift ve YorumlarÄ±:\n",
        "Analiz sonucunda en gÃ¼Ã§lÃ¼ pozitif iliÅŸkiye sahip Ã§iftler ÅŸunlardÄ±r:\n",
        "\n",
        "**mean radius - mean perimeter (Korelasyon: 0.998):** Bir dairenin yarÄ±Ã§apÄ± (radius) arttÄ±kÃ§a Ã§evresi (perimeter) de matematiksel olarak ($2\\pi r$) artar. Bu ikisi arasÄ±ndaki iliÅŸkinin neredeyse 1 olmasÄ± (mÃ¼kemmel korelasyon), aslÄ±nda bu iki deÄŸiÅŸkenin model iÃ§in aynÄ± bilgiyi taÅŸÄ±dÄ±ÄŸÄ±nÄ± gÃ¶sterir. \"Multicollinearity\" (Ã‡oklu BaÄŸlantÄ±) sorunu yaratabilirler.\n",
        "\n",
        "**worst radius - worst perimeter (Korelasyon: 0.994):** Ä°lk maddedeki iliÅŸkinin aynÄ±sÄ±, \"en kÃ¶tÃ¼\" (worst) deÄŸerler iÃ§in de geÃ§erlidir. Geometrik zorunluluktan kaynaklanan bu iliÅŸki biyolojik deÄŸil, matematikseldir.\n",
        "\n",
        "**mean radius - mean area (Korelasyon: 0.987):** YarÄ±Ã§ap ve Alan ($\\pi r^2$) arasÄ±ndaki iliÅŸkidir. YarÄ±Ã§ap bÃ¼yÃ¼dÃ¼kÃ§e alan karesel olarak bÃ¼yÃ¼r, bu da Ã§ok gÃ¼Ã§lÃ¼ bir pozitif iliÅŸki doÄŸurur."
      ],
      "metadata": {
        "id": "52CPTBotizI7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AdÄ±m 3.3: TÃ¼m Ã–zellikler Ä°Ã§in Boxplot ve Yorumu**"
      ],
      "metadata": {
        "id": "zTyyUq02lGwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3.3 Boxplot Analizi (TÃ¼m Ã–zellikler)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Ã–zellik isimlerini alalÄ±m (hedef deÄŸiÅŸken hariÃ§)\n",
        "features = df.columns[:-1]\n",
        "num_features = len(features)\n",
        "\n",
        "# 6 satÄ±r x 5 sÃ¼tunluk Ä±zgara\n",
        "num_rows = math.ceil(num_features / 5)\n",
        "num_cols = 5\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(20, 25))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(features):\n",
        "    sns.boxplot(y=df[col], ax=axes[i], color='skyblue')\n",
        "    axes[i].set_title(col, fontsize=10)\n",
        "    axes[i].set_ylabel(\"\")\n",
        "\n",
        "# BoÅŸ kalanlarÄ± gizle\n",
        "for j in range(i + 1, len(axes)):\n",
        "    fig.delaxes(axes[j])\n",
        "\n",
        "plt.suptitle(\"BÃ¶lÃ¼m 3.3: TÃ¼m Ã–znitelikler Ä°Ã§in Boxplot Analizi\", fontsize=16, y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "05Xly0ZXlHgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AykÄ±rÄ± DeÄŸer (Outlier) Yorumu:** Grafikler incelendiÄŸinde, Ã¶zellikle area (alan), perimeter (Ã§evre) ve concavity (iÃ§bÃ¼keylik) gibi boyut ve ÅŸekil bozukluÄŸunu ifade eden Ã¶zniteliklerde Ã¼st sÄ±nÄ±rÄ±n (Upper Whisker) Ã¼zerinde yoÄŸun aykÄ±rÄ± deÄŸerler gÃ¶rÃ¼lmektedir.\n",
        "\n",
        "Nedeni: Kanserli hÃ¼crelerin biyolojik doÄŸasÄ± gereÄŸi \"kontrolsÃ¼z bÃ¼yÃ¼me\" eÄŸilimi vardÄ±r. Bu durum, bazÄ± hÃ¼crelerin normalden Ã§ok daha bÃ¼yÃ¼k boyutlara ve bozuk ÅŸekillere sahip olmasÄ±na neden olur.\n",
        "\n",
        "Karar: Grafikte \"aykÄ±rÄ±\" (outlier) olarak gÃ¶rÃ¼nen bu noktalar, veri hatasÄ± deÄŸil, hastalÄ±ÄŸÄ±n en belirgin (malignant) Ã¶rnekleridir. Bu nedenle, modelin kanserli vakalarÄ± doÄŸru tanÄ±masÄ± (hassasiyet) iÃ§in bu deÄŸerler silinmemiÅŸ, veri setinde korunmuÅŸtur."
      ],
      "metadata": {
        "id": "pHN02dVDlWFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Veri Setinin BÃ¶lÃ¼nmesi**"
      ],
      "metadata": {
        "id": "3tpZQ0FRmiuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 1. Ã–nce HafÄ±zayÄ± Tazeleyelim (Unutulan KÄ±sÄ±m) ---\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Ã–lÃ§eklendirme (Bunu yapmadÄ±ÄŸÄ± iÃ§in X_scaled yok diyordu)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# --- 2. Åimdi Senin Kodun (BÃ¶lme Ä°ÅŸlemi) ---\n",
        "\n",
        "# 1. ADIM: Ã–nce Test setini (%20) ayÄ±ralÄ±m. Geriye %80 kalacak.\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.20, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 2. ADIM: Kalan %80'lik kÄ±smÄ± (X_temp), Train (%70) ve Validation (%10) olarak bÃ¶lelim.\n",
        "# Matematik HesabÄ±: 0.10 / 0.80 = 0.125\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "# SonuÃ§larÄ± GÃ¶relim\n",
        "print(f\"Toplam Veri SayÄ±sÄ±: {len(X)}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"EÄŸitim Seti (Train) Boyutu      : {X_train.shape} -> Oran: %{len(X_train)/len(X)*100:.1f} (Hedef %70)\")\n",
        "print(f\"DoÄŸrulama Seti (Val) Boyutu     : {X_val.shape}   -> Oran: %{len(X_val)/len(X)*100:.1f} (Hedef %10)\")\n",
        "print(f\"Test Seti (Test) Boyutu         : {X_test.shape}  -> Oran: %{len(X_test)/len(X)*100:.1f} (Hedef %20)\")"
      ],
      "metadata": {
        "id": "h3_isqLZlevX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Veri Setinin BÃ¶lÃ¼nmesi** Modelin genelleme yeteneÄŸini doÄŸru Ã¶lÃ§mek ve aÅŸÄ±rÄ± Ã¶ÄŸrenmenin (overfitting) Ã¶nÃ¼ne geÃ§mek amacÄ±yla veri seti Ã¼Ã§ ayrÄ± parÃ§aya ayrÄ±lmÄ±ÅŸtÄ±r:\n",
        "\n",
        "EÄŸitim (Training - %70): Modelin aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncellemek ve Ã¶ÄŸrenmek iÃ§in kullandÄ±ÄŸÄ± ana veri grubu.\n",
        "\n",
        "DoÄŸrulama (Validation - %10): EÄŸitim sÄ±rasÄ±nda modelin performansÄ±nÄ± anlÄ±k olarak izlemek ve hiperparametre optimizasyonu yapmak iÃ§in ayrÄ±lan, modelin eÄŸitimde gÃ¶rmediÄŸi veri grubu.\n",
        "\n",
        "Test (%20): Model tamamlandÄ±ktan sonra nihai baÅŸarÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in saklanan, eÄŸitim ve validasyon sÃ¼reÃ§lerinde hiÃ§bir ÅŸekilde kullanÄ±lmayan veri grubu.\n",
        "\n",
        "YÃ¶ntem: BÃ¶lme iÅŸlemi train_test_split fonksiyonu iki aÅŸamalÄ± kullanÄ±larak gerÃ§ekleÅŸtirilmiÅŸtir. SÄ±nÄ±f dengesizliÄŸini Ã¶nlemek adÄ±na her iki adÄ±mda da stratify=y parametresi kullanÄ±lmÄ±ÅŸ, bÃ¶ylece kanserli/saÄŸlÄ±klÄ± hasta oranÄ±nÄ±n her parÃ§ada eÅŸit daÄŸÄ±lmasÄ± saÄŸlanmÄ±ÅŸtÄ±r."
      ],
      "metadata": {
        "id": "eC6zwC-Inwhe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Veri Ã–lÃ§eklendirme (Scaling)**"
      ],
      "metadata": {
        "id": "-_6NFCquqLSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**StandardScaler**\n",
        "YSA'nÄ±n KimyasÄ±: Yapay Sinir AÄŸlarÄ± (bizim kullanacaÄŸÄ±mÄ±z MLP modeli), matematiksel olarak 0 etrafÄ±nda toplanmÄ±ÅŸ (merkezlenmiÅŸ) verilerle Ã§ok daha hÄ±zlÄ± ve doÄŸru Ã§alÄ±ÅŸÄ±r.\n",
        "\n",
        "Biyolojik Veri: TÄ±bbi Ã¶lÃ§Ã¼mler (kan deÄŸerleri, hÃ¼cre boyutu vb.) genelde doÄŸada \"Ã‡an EÄŸrisi\" (Normal DaÄŸÄ±lÄ±m) ÅŸeklinde daÄŸÄ±lÄ±r. StandardScaler tam olarak bu daÄŸÄ±lÄ±ma uygundur.\n",
        "Verimizde outlierlar olduÄŸu iÃ§in MinMaxScaler tercih edilmez."
      ],
      "metadata": {
        "id": "Fp4nuPUZqkBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Veri Ã–lÃ§eklendirme (Scaling)\n",
        "# SeÃ§ilen YÃ¶ntem: StandardScaler\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Scaler nesnesini oluÅŸturalÄ±m\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# X verisini (Ã¶zellikleri) verip, dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ halini alalÄ±m\n",
        "# fit: OrtalamayÄ± ve Standart SapmayÄ± hesaplar.\n",
        "# transform: FormÃ¼lÃ¼ uygular (DeÄŸer - Ortalama) / Std.Sapma\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Kontrol edelim (Ä°lk satÄ±rÄ±n ilk Ã¶zelliÄŸine bakalÄ±m)\n",
        "print(\"Ã–lÃ§ekleme Ã–ncesi Ä°lk DeÄŸer (Mean Radius):\", X[0][0])\n",
        "print(\"Ã–lÃ§ekleme SonrasÄ± Ä°lk DeÄŸer (Mean Radius):\", X_scaled[0][0])\n",
        "\n",
        "# Boyut kontrolÃ¼ (Veri kaybolmadÄ± di mi?)\n",
        "print(f\"X_scaled boyutu: {X_scaled.shape}\")"
      ],
      "metadata": {
        "id": "mCKcTSqUqus_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veri setindeki farklÄ± Ã¶zniteliklerin (Ã–rn: Alan ve PÃ¼rÃ¼zsÃ¼zlÃ¼k) sayÄ±sal bÃ¼yÃ¼klÃ¼kleri arasÄ±ndaki uÃ§urumu kapatmak ve Yapay Sinir AÄŸÄ± modelinin optimizasyon sÃ¼recini (gradient descent) hÄ±zlandÄ±rmak amacÄ±yla Ã¶lÃ§eklendirme iÅŸlemi uygulanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "YÃ¶ntem olarak StandardScaler (Z-Skor Normalizasyonu) tercih edilmiÅŸtir.\n",
        "\n",
        "Bu iÅŸlemle tÃ¼m Ã¶znitelikler, ortalamasÄ± 0 ve varyansÄ± 1 olacak ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "BÃ¶ylece modelin bÃ¼yÃ¼k sayÄ±sal deÄŸere sahip Ã¶zellikleri \"daha Ã¶nemli\" sanmasÄ±nÄ±n Ã¶nÃ¼ne geÃ§ilmiÅŸtir. Elde edilen veri X_scaled deÄŸiÅŸkenine kaydedilmiÅŸtir."
      ],
      "metadata": {
        "id": "3kZoGpnqq2jT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. FarklÄ± MLP Modellerinin KurulmasÄ±**"
      ],
      "metadata": {
        "id": "hhVuBsf7uJHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 6. FarklÄ± MLP Modellerinin KurulmasÄ±\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Modelleri bir sÃ¶zlÃ¼k (dictionary) iÃ§inde tanÄ±mlÄ±yoruz.\n",
        "# BÃ¶ylece hepsini tek bir dÃ¶ngÃ¼de yÃ¶netebileceÄŸiz.\n",
        "\n",
        "mlp_modelleri = {\n",
        "    \"Model 1 (Basit)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(16,),\n",
        "        activation=\"relu\",\n",
        "        learning_rate_init=0.001,\n",
        "        random_state=42, max_iter=1000\n",
        "    ),\n",
        "    \"Model 2 (Orta)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(32, 16),\n",
        "        activation=\"relu\",\n",
        "        learning_rate_init=0.005,\n",
        "        random_state=42, max_iter=1000\n",
        "    ),\n",
        "    \"Model 3 (GeniÅŸ)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(64, 64),\n",
        "        activation=\"tanh\",\n",
        "        learning_rate_init=0.001,\n",
        "        random_state=42, max_iter=1000\n",
        "    ),\n",
        "    \"Model 4 (Derin)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64, 32),\n",
        "        activation=\"relu\",\n",
        "        learning_rate_init=0.0005,\n",
        "        random_state=42, max_iter=1000\n",
        "    ),\n",
        "    \"Model 5 (DÃ¼ÅŸÃ¼k HÄ±z)\": MLPClassifier(\n",
        "        hidden_layer_sizes=(32,),\n",
        "        activation=\"relu\",\n",
        "        learning_rate_init=0.0001,\n",
        "        random_state=42, max_iter=1000\n",
        "    )\n",
        "}\n",
        "\n",
        "print(\"5 FarklÄ± MLP Modeli BaÅŸarÄ±yla TanÄ±mlandÄ± ve HafÄ±zaya AlÄ±ndÄ±.\")\n",
        "print(\"Modeller EÄŸitime HazÄ±r.\")"
      ],
      "metadata": {
        "id": "Uw9JtPKxuH37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bu adÄ±mda, Yapay Sinir AÄŸÄ± (MLP) mimarisindeki yapÄ±sal deÄŸiÅŸikliklerin ve hiperparametre seÃ§imlerinin model baÅŸarÄ±sÄ±na etkisini gÃ¶zlemlemek amacÄ±yla 5 farklÄ± model senaryosu kurgulanmÄ±ÅŸtÄ±r. HenÃ¼z eÄŸitim aÅŸamasÄ±na geÃ§ilmemiÅŸ, modeller scikit-learn kÃ¼tÃ¼phanesi kullanÄ±larak nesne olarak tanÄ±mlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Modellerin Kurgulanma AmaÃ§larÄ±:\n",
        "\n",
        "Referans Model (Model 1): Tek gizli katman (16 nÃ¶ron) ile en basit yapÄ±dÄ±r. DiÄŸer karmaÅŸÄ±k modellerin baÅŸarÄ±sÄ±nÄ± kÄ±yaslamak iÃ§in taban (baseline) olarak kullanÄ±lacaktÄ±r.\n",
        "\n",
        "Derinlik Etkisi (Model 2 ve Model 4): Model 2 (2 katman) ve Model 4 (3 katman) ile \"AÄŸ derinleÅŸtikÃ§e (katman sayÄ±sÄ± arttÄ±kÃ§a) Ã¶ÄŸrenme performansÄ± artÄ±yor mu yoksa ezberleme (overfitting) mi baÅŸlÄ±yor?\" sorusuna yanÄ±t aranacaktÄ±r.\n",
        "\n",
        "Aktivasyon Fonksiyonu Etkisi (Model 3): Genelde kullanÄ±lan ReLU yerine Tanh fonksiyonu seÃ§ilerek, veri daÄŸÄ±lÄ±mÄ±na uygunluÄŸu test edilecektir.\n",
        "\n",
        "Ã–ÄŸrenme HÄ±zÄ± Hassasiyeti (Model 5): Ã–ÄŸrenme oranÄ± (learning rate) 0.0001 seviyesine dÃ¼ÅŸÃ¼rÃ¼lerek, modelin daha yavaÅŸ ama daha kararlÄ± (fine-tuning) bir Ã¶ÄŸrenme gerÃ§ekleÅŸtirip gerÃ§ekleÅŸtirmediÄŸi analiz edilecektir.\n",
        "\n",
        "Model 1, 2, 4, 5 (ReLU): Modern, hÄ±zlÄ±, negatifleri susturan modeller.\n",
        "\n",
        "Model 3 (Tanh): Daha klasik, negatif deÄŸerlere de anlam yÃ¼kleyen, veriyi sÄ±kÄ±ÅŸtÄ±ran model."
      ],
      "metadata": {
        "id": "S2i_WYHjqz_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.Validation PerformanslarÄ±nÄ±n Ã–lÃ§Ã¼lmesi**"
      ],
      "metadata": {
        "id": "m0Mq4XgvrI0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 7. Validation PerformanslarÄ±nÄ±n Ã–lÃ§Ã¼lmesi\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# SonuÃ§larÄ± tutacaÄŸÄ±mÄ±z boÅŸ bir liste\n",
        "performans_sonuclari = []\n",
        "\n",
        "print(\"Modeller EÄŸitiliyor ve DeÄŸerlendiriliyor...\\n\")\n",
        "\n",
        "# DÃ¶ngÃ¼ ile her modeli sÄ±rayla alalÄ±m\n",
        "for model_adi, model in mlp_modelleri.items():\n",
        "\n",
        "    # 1. EÄÄ°TÄ°M (TRAINING): Modeli X_train ile eÄŸitiyoruz\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # 2. TAHMÄ°N (PREDICTION): Validation setine (X_val) soruyoruz\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # ROC-AUC iÃ§in \"OlasÄ±lÄ±k\" (Probability) deÄŸeri gerekir (0 veya 1 deÄŸil, %80 ihtimal gibi)\n",
        "    # [:, 1] diyerek sadece \"SÄ±nÄ±f 1\" (Pozitif/Hasta) olma ihtimalini alÄ±yoruz.\n",
        "    y_proba = model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "    # 3. METRÄ°KLERÄ°N HESAPLANMASI\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    prec = precision_score(y_val, y_pred)\n",
        "    rec = recall_score(y_val, y_pred)\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    auc = roc_auc_score(y_val, y_proba)\n",
        "\n",
        "    # SonuÃ§larÄ± listeye ekle\n",
        "    performans_sonuclari.append({\n",
        "        \"Model AdÄ±\": model_adi,\n",
        "        \"Accuracy (DoÄŸruluk)\": acc,\n",
        "        \"Precision (Kesinlik)\": prec,\n",
        "        \"Recall (DuyarlÄ±lÄ±k)\": rec,\n",
        "        \"F1-Score\": f1,\n",
        "        \"ROC-AUC\": auc\n",
        "    })\n",
        "\n",
        "# Listeyi Pandas Tablosuna Ã§evir\n",
        "df_performans = pd.DataFrame(performans_sonuclari)\n",
        "\n",
        "# Tabloyu ekrana basalÄ±m (Puanlara gÃ¶re sÄ±ralayalÄ±m)\n",
        "# ROC-AUC puanÄ±na gÃ¶re bÃ¼yÃ¼kten kÃ¼Ã§Ã¼ÄŸe sÄ±rala\n",
        "df_performans = df_performans.sort_values(by=\"ROC-AUC\", ascending=False)\n",
        "\n",
        "print(df_performans.to_string(index=False))\n",
        "\n",
        "# En iyi modeli bir kenara not edelim (Otomatik seÃ§im)\n",
        "en_iyi_model_adi = df_performans.iloc[0][\"Model AdÄ±\"]\n",
        "print(f\"\\nğŸ† Tabloya gÃ¶re Validasyon setinde en baÅŸarÄ±lÄ± model: {en_iyi_model_adi}\")"
      ],
      "metadata": {
        "id": "n-Ngw0b_rAk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy (DoÄŸruluk): Modelin genel olarak ne kadar doÄŸru bildiÄŸi. (Toplam DoÄŸru / Toplam Hasta).\n",
        "\n",
        "Precision (Kesinlik): Modelin \"Kanser\" dediklerinin gerÃ§ekten kaÃ§Ä± kanser? (YanlÄ±ÅŸ alarm vermeme baÅŸarÄ±sÄ±).\n",
        "\n",
        "Recall (DuyarlÄ±lÄ±k): GerÃ§ekten kanser olanlarÄ±n kaÃ§Ä±nÄ± yakalayabildik? (GÃ¶zden kaÃ§Ä±rmama baÅŸarÄ±sÄ± - TÄ±pta en kritik metriktir!).\n",
        "\n",
        "F1-Score: Precision ve Recall'un harmonik ortalamasÄ±dÄ±r. Dengesiz veri setlerinde Accuracy'den daha gÃ¼venilir bir baÅŸarÄ± Ã¶lÃ§Ã¼tÃ¼dÃ¼r.\n",
        "\n",
        "ROC-AUC: Modelin pozitif ve negatif sÄ±nÄ±flarÄ± birbirinden ayÄ±rma yeteneÄŸidir. 1'e ne kadar yakÄ±nsa model o kadar mÃ¼kemmeldir.\n",
        "\n",
        "En Ä°yi Genel Performans (Model 3): ROC-AUC (0.995) deÄŸeri baz alÄ±ndÄ±ÄŸÄ±nda, Model 3 (GeniÅŸ Mimari), pozitif ve negatif sÄ±nÄ±flarÄ± birbirinden ayÄ±rma konusunda en yÃ¼ksek baÅŸarÄ±yÄ± gÃ¶stermiÅŸtir.\n",
        "\n",
        "Kusursuz \"Recall\" BaÅŸarÄ±sÄ± (Model 1 ve Model 4): Tablo incelendiÄŸinde, hem en basit yapÄ±daki Model 1'in hem de en karmaÅŸÄ±k yapÄ±daki Model 4'Ã¼n Recall (DuyarlÄ±lÄ±k) skorunun 1.0 (Tam Puan) olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "TÄ±bbi Yorum: Bu iki model de validasyon setindeki hiÃ§bir kanserli vakayÄ± kaÃ§Ä±rmamÄ±ÅŸ, tÃ¼m teÅŸhisleri doÄŸru yapmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Fark: Ancak Model 4'Ã¼n genel puanÄ±nÄ±n (ROC-AUC) Model 3'ten dÃ¼ÅŸÃ¼k olmasÄ±, \"kanseri kaÃ§Ä±rmayayÄ±m derken saÄŸlÄ±klÄ± insanlara yanlÄ±ÅŸlÄ±kla hasta deme\" (False Positive) riskinin Model 3'e gÃ¶re daha yÃ¼ksek olduÄŸunu dÃ¼ÅŸÃ¼ndÃ¼rmektedir.\n",
        "\n",
        "SonuÃ§: Model 1 ve Model 4'Ã¼n kusursuz duyarlÄ±lÄ±ÄŸÄ±na raÄŸmen; yanlÄ±ÅŸ alarmlarÄ± en iyi yÃ¶neten ve genel dengesi en yÃ¼ksek olan Model 3 (GeniÅŸ Mimari), final modeli olarak seÃ§ilmiÅŸtir."
      ],
      "metadata": {
        "id": "0oUHWkUFwxkJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. En Ä°yi Modelin Test Ãœzerinde DeÄŸerlendirilmesi**"
      ],
      "metadata": {
        "id": "B1O8sLNOzD51"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.1 Performans Metrikleri**"
      ],
      "metadata": {
        "id": "Mqyk32bJz1bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 8. En Ä°yi Modelin Test Ãœzerinde DeÄŸerlendirilmesi\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# Ã–nceki adÄ±mda (Step 7) belirlediÄŸimiz en iyi modeli Ã§aÄŸÄ±ralÄ±m\n",
        "# (EÄŸer hafÄ±zada yoksa manuel olarak: secilen_model = mlp_modelleri[\"Model 3 (GeniÅŸ)\"])\n",
        "secilen_model = mlp_modelleri[en_iyi_model_adi]\n",
        "\n",
        "print(f\"SEÃ‡Ä°LEN MODEL: {en_iyi_model_adi}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# 1. TAHMÄ°N (TEST SETÄ° ÃœZERÄ°NDE): Kasadaki X_test'i Ã§Ä±karÄ±yoruz\n",
        "y_pred_test = secilen_model.predict(X_test)\n",
        "y_proba_test = secilen_model.predict_proba(X_test)[:, 1] # ROC-AUC iÃ§in olasÄ±lÄ±k\n",
        "\n",
        "# 2. METRÄ°KLERÄ°N HESAPLANMASI\n",
        "test_acc = accuracy_score(y_test, y_pred_test)\n",
        "test_prec = precision_score(y_test, y_pred_test)\n",
        "test_rec = recall_score(y_test, y_pred_test)\n",
        "test_f1 = f1_score(y_test, y_pred_test)\n",
        "test_auc = roc_auc_score(y_test, y_proba_test)\n",
        "\n",
        "# 3. SONUÃ‡LARI RAPORLAMA\n",
        "print(f\"Test Seti Accuracy (DoÄŸruluk) : {test_acc:.4f}\")\n",
        "print(f\"Test Seti Precision (Kesinlik): {test_prec:.4f}\")\n",
        "print(f\"Test Seti Recall (DuyarlÄ±lÄ±k) : {test_rec:.4f}\")\n",
        "print(f\"Test Seti F1-Score            : {test_f1:.4f}\")\n",
        "print(f\"Test Seti ROC-AUC             : {test_auc:.4f}\")"
      ],
      "metadata": {
        "id": "pV1kC7ehwxX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validasyon aÅŸamasÄ±nda en iyi model olarak seÃ§ilen Model 3 (GeniÅŸ Mimari), hiÃ§ gÃ¶rmediÄŸi Test seti Ã¼zerinde deÄŸerlendirilmiÅŸ ve ÅŸu sonuÃ§lar elde edilmiÅŸtir:\n",
        "\n",
        "YÃ¼ksek AyrÄ±ÅŸtÄ±rma GÃ¼cÃ¼ (ROC-AUC: 0.9940): Modelin kanserli ve saÄŸlÄ±klÄ± hÃ¼creleri birbirinden ayÄ±rma baÅŸarÄ±sÄ± %99.4 seviyesindedir. Bu deÄŸer, modelin rastgele tahmin yapmaktan Ã§ok uzak, neredeyse mÃ¼kemmel bir sÄ±nÄ±flandÄ±rma yeteneÄŸine sahip olduÄŸunu kanÄ±tlar.\n",
        "\n",
        "MÃ¼kemmel Denge (Precision = Recall = 0.9722): TÄ±bbi modellerde genellikle Hassasiyet (Recall) artarken Kesinlik (Precision) dÃ¼ÅŸer. Ancak Model 3'te bu iki deÄŸerin ve F1 skorunun eÅŸit (0.97) Ã§Ä±kmasÄ±, modelin karar mekanizmasÄ±nÄ±n son derece kararlÄ± (stable) olduÄŸunu gÃ¶stermektedir. YanlÄ±ÅŸ negatif (kanseri kaÃ§Ä±rma) ve yanlÄ±ÅŸ pozitif (yanlÄ±ÅŸ alarm) sayÄ±larÄ± dengelidir.\n",
        "\n",
        "Genelleme BaÅŸarÄ±sÄ± (Overfitting Yok): Validasyon aÅŸamasÄ±ndaki ROC-AUC skoru (0.995) ile Test aÅŸamasÄ±ndaki ROC-AUC skoru (0.994) neredeyse birebir aynÄ±dÄ±r. Bu durum, modelin eÄŸitim verisini ezberlemediÄŸini, gerÃ§ekten Ã¶ÄŸrendiÄŸini ve yeni gelen hasta verilerinde de aynÄ± yÃ¼ksek baÅŸarÄ±yÄ± sÃ¼rdÃ¼rebildiÄŸini doÄŸrulamaktadÄ±r."
      ],
      "metadata": {
        "id": "i3p8C5CpzzZh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.2 Confusion Matrix**"
      ],
      "metadata": {
        "id": "bSGVt6YGz0j8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 8.2 Confusion Matrix (KarmaÅŸÄ±klÄ±k Matrisi)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. Matrisi Hesapla\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "# 2. GÃ¶rselleÅŸtirme (Heatmap)\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# annot=True: KutularÄ±n iÃ§ine sayÄ±larÄ± yaz\n",
        "# fmt='d': SayÄ±larÄ± tam sayÄ± (integer) olarak yaz (bilimsel gÃ¶sterim yapma)\n",
        "# cmap='Blues': Mavi tonlarÄ±nÄ± kullan\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Tahmin: Kanser (0)', 'Tahmin: Temiz (1)'],\n",
        "            yticklabels=['GerÃ§ek: Kanser (0)', 'GerÃ§ek: Temiz (1)'])\n",
        "\n",
        "plt.ylabel('GerÃ§ek Durum (Doktorun KararÄ±)')\n",
        "plt.xlabel('Modelin Tahmini (Yapay Zeka)')\n",
        "plt.title(f'Confusion Matrix - {en_iyi_model_adi}')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nlCFh6ruz-Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelin test seti Ã¼zerindeki tahminleri Confusion Matrix ile incelenmiÅŸtir. Test setinde toplam 114 hasta (42 Kanserli, 72 SaÄŸlÄ±klÄ±) bulunmaktadÄ±r.\n",
        "\n",
        "DetaylÄ± Analiz:\n",
        "\n",
        "DoÄŸru Tespitler (BaÅŸarÄ±):\n",
        "\n",
        "Sol Ãœst (40): Model, 42 kanserli hastanÄ±n 40 tanesini baÅŸarÄ±yla yakalamÄ±ÅŸ ve doÄŸru alarm vermiÅŸtir.\n",
        "\n",
        "SaÄŸ Alt (70): Model, 72 saÄŸlÄ±klÄ± bireyin 70 tanesini doÄŸru bilmiÅŸ ve \"Temiz\" raporu vermiÅŸtir.\n",
        "\n",
        "Genel BaÅŸarÄ±: Toplam 114 hastanÄ±n 110'u (%96.5) hatasÄ±z sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r.\n",
        "\n",
        "HatalÄ± Tespitler (Risk Analizi):\n",
        "\n",
        "SaÄŸ Ãœst (2) - Kritik Hata (Missed Cancer): GerÃ§ekte kanser olan 2 hasta, model tarafÄ±ndan yanlÄ±ÅŸlÄ±kla \"Temiz\" olarak sÄ±nÄ±flandÄ±rÄ±lmÄ±ÅŸtÄ±r. TÄ±bbi aÃ§Ä±dan en aza indirilmesi gereken hata tÃ¼rÃ¼ budur.\n",
        "\n",
        "Sol Alt (2) - YanlÄ±ÅŸ Alarm (False Alarm): GerÃ§ekte saÄŸlÄ±klÄ± olan 2 kiÅŸiye, model tarafÄ±ndan yanlÄ±ÅŸlÄ±kla \"Kanser\" denilmiÅŸtir. Bu durum hasta psikolojisi iÃ§in olumsuz olsa da hayati risk taÅŸÄ±maz.\n",
        "\n",
        "SonuÃ§: Modelin hatalarÄ± (2 Kritik Hata, 2 YanlÄ±ÅŸ Alarm) sayÄ±sal olarak birbirine eÅŸittir ve oldukÃ§a dÃ¼ÅŸÃ¼ktÃ¼r. Modelin hem kanseri yakalama hem de saÄŸlÄ±klÄ± insanÄ± ayÄ±rt etme yeteneÄŸi dengelidir."
      ],
      "metadata": {
        "id": "2vQCsRxY0jct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8.3 ROC EÄŸrisi**"
      ],
      "metadata": {
        "id": "-l4OTG461EMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 8.3 ROC EÄŸrisi ve AUC DeÄŸeri\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# KarÅŸÄ±laÅŸtÄ±rÄ±lacak en iyi 3 model\n",
        "secilecek_modeller = [\"Model 3 (GeniÅŸ)\", \"Model 1 (Basit)\", \"Model 4 (Derin)\"]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "for isim in secilecek_modeller:\n",
        "    model = mlp_modelleri[isim]\n",
        "\n",
        "    # 1. OlasÄ±lÄ±klarÄ± Al (Kanser olma ihtimali - SÃ¼tun 1)\n",
        "    # ROC Ã§izmek iÃ§in 0/1 tahmini deÄŸil, %85, %90 gibi olasÄ±lÄ±klar gerekir.\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # 2. EÄŸri Verilerini Hesapla (FPR, TPR)\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # 3. Ã‡iz\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'{isim} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "# Referans Ã‡izgisi (Åans Eseri / YazÄ± Tura - %50)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (YanlÄ±ÅŸ Alarm OranÄ±)')\n",
        "plt.ylabel('True Positive Rate (Yakalanan Kanser OranÄ±)')\n",
        "plt.title('Modellerin ROC EÄŸrisi KarÅŸÄ±laÅŸtÄ±rmasÄ±')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SFneM-jU04Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test seti Ã¼zerinde en baÅŸarÄ±lÄ± Ã¼Ã§ modelin (Model 3, Model 1, Model 4) ROC eÄŸrileri Åekil X'te gÃ¶rselleÅŸtirilmiÅŸtir.\n",
        "\n",
        "1. Genel Performans (MÃ¼kemmelliÄŸe YakÄ±n): Grafikteki Ã¼Ã§ eÄŸrinin de sol Ã¼st kÃ¶ÅŸeye (True Positive Rate = 1, False Positive Rate = 0) adeta \"yapÄ±ÅŸtÄ±ÄŸÄ±\" gÃ¶rÃ¼lmektedir. Rastgele tahmin Ã§izgisinden (Lacivert kesikli Ã§izgi) bu denli uzaklaÅŸmalarÄ±, modellerin ayÄ±rt etme gÃ¼cÃ¼nÃ¼n Ã§ok yÃ¼ksek olduÄŸunu kanÄ±tlar.\n",
        "\n",
        "2. Modellerin KÄ±yaslanmasÄ±:\n",
        "\n",
        "Model 3 (Mavi Ã‡izgi): 0.9940 AUC skoru ile eÄŸrinin altÄ±nda en geniÅŸ alanÄ± kapsayan ve matematiksel olarak en baÅŸarÄ±lÄ± model olmuÅŸtur.\n",
        "\n",
        "Model 4 (YeÅŸil Ã‡izgi): 0.9931 AUC skoru ile Model 3'Ã¼ Ã§ok yakÄ±ndan takip etmektedir. Derin mimari (3 katman) ile GeniÅŸ mimari (2 katman/tanh) arasÄ±ndaki farkÄ±n bu veri setinde marjinal olduÄŸu gÃ¶rÃ¼lmÃ¼ÅŸtÃ¼r.\n",
        "\n",
        "Model 1 (Turuncu Ã‡izgi): En basit model olmasÄ±na raÄŸmen 0.9904 gibi Ã§ok yÃ¼ksek bir skor elde etmiÅŸtir. Ancak grafiÄŸin baÅŸlangÄ±Ã§ noktasÄ±nda (FPR < 0.05 olduÄŸu bÃ¶lgede) Mavi ve YeÅŸil Ã§izginin hafifÃ§e altÄ±nda kaldÄ±ÄŸÄ±, yani \"yanlÄ±ÅŸ alarm vermeden kanseri yakalama\" konusunda diÄŸer ikisinden bir tÄ±k geride olduÄŸu gÃ¶zlemlenmiÅŸtir.\n",
        "\n",
        "3. EÄŸrinin Åekli ve EÅŸik DeÄŸeri Yorumu: EÄŸrilerin neredeyse dik bir aÃ§Ä±yla yÃ¼kselmesi ÅŸunu ifade eder: Model, eÅŸik deÄŸeri (threshold) Ã§ok katÄ± tutulsa bile (yani YanlÄ±ÅŸ Alarm OranÄ± %0-%5 arasÄ±ndayken bile), kanserli vakalarÄ±n yaklaÅŸÄ±k %90-%95'ini (True Positive Rate) yakalayabilmektedir. Bu, tÄ±bbi bir sÄ±nÄ±flandÄ±rma sistemi iÃ§in son derece gÃ¼venilir bir tablodur."
      ],
      "metadata": {
        "id": "gPaR06Zy23W2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **9. Optuna ile Hiperparametre Optimizasyonu (150 Deneme)**"
      ],
      "metadata": {
        "id": "oS5jhgP5z4-B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.1 Optuna Study TanÄ±mÄ±**"
      ],
      "metadata": {
        "id": "RjyQz2Cm6fB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ã–nce kÃ¼tÃ¼phaneyi yÃ¼kleyelim (EÄŸer yÃ¼klÃ¼ deÄŸilse)\n",
        "!pip install optuna\n",
        "\n",
        "import optuna\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 9.1 Optuna Study TanÄ±mÄ± ve 150 Deneme\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def objective(trial):\n",
        "    # 1. PARAMETRE UZAYI (Optuna'nÄ±n deneyeceÄŸi aralÄ±klar)\n",
        "\n",
        "    # Katman YapÄ±sÄ±: Tek katmanlÄ± mÄ± olsun, Ã§ift mi, Ã¼Ã§ mÃ¼? KaÃ§ nÃ¶ron?\n",
        "    n_layers = trial.suggest_int('n_layers', 1, 3) # 1 ile 3 katman arasÄ±\n",
        "    layers = []\n",
        "    for i in range(n_layers):\n",
        "        # Her katman iÃ§in 16 ile 128 arasÄ±nda bir nÃ¶ron sayÄ±sÄ± seÃ§\n",
        "        layers.append(trial.suggest_int(f'n_units_l{i}', 16, 128))\n",
        "\n",
        "    # Aktivasyon Fonksiyonu: relu mu, tanh mÄ±, logistic mi?\n",
        "    activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'logistic'])\n",
        "\n",
        "    # Ã–ÄŸrenme OranÄ± (Learning Rate): Logaritmik olarak ara (0.0001 ile 0.1 arasÄ±)\n",
        "    lr_init = trial.suggest_float('learning_rate_init', 1e-4, 1e-1, log=True)\n",
        "\n",
        "    # Alpha (Regularization - Ezberbozan): 0.0001 ile 0.1 arasÄ±\n",
        "    alpha = trial.suggest_float('alpha', 1e-4, 1e-1, log=True)\n",
        "\n",
        "    # 2. MODEL KURULUMU\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=tuple(layers),\n",
        "        activation=activation,\n",
        "        learning_rate_init=lr_init,\n",
        "        alpha=alpha,\n",
        "        random_state=42,\n",
        "        max_iter=500  # Her deneme iÃ§in 500 adÄ±m yeterli\n",
        "    )\n",
        "\n",
        "    # 3. EÄÄ°TÄ°M VE TEST\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # 4. HEDEF METRÄ°K (F1-Score'u maksimize etmeye Ã§alÄ±ÅŸÄ±yoruz)\n",
        "    # Kanser teÅŸhisinde denge Ã¶nemli olduÄŸu iÃ§in Accuracy yerine F1 seÃ§tik.\n",
        "    score = f1_score(y_val, y_pred)\n",
        "\n",
        "    return score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# OPTÄ°MÄ°ZASYONU BAÅLAT (150 TRIAL)\n",
        "# ---------------------------------------------------------\n",
        "print(\"Optuna Optimizasyonu BaÅŸlÄ±yor (150 Deneme)...\")\n",
        "\n",
        "# Study oluÅŸtur (YÃ¶n: Maximize -> PuanÄ± yÃ¼kseltmeye Ã§alÄ±ÅŸ)\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "\n",
        "# 150 kez dene!\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(f\"En Ä°yi Deneme (Best Trial):\")\n",
        "print(f\"  DeÄŸer (F1-Score): {study.best_trial.value:.4f}\")\n",
        "print(\"  En Ä°yi Parametreler:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "WkNvzNEN6eGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimizasyon SonuÃ§larÄ±nÄ±n DeÄŸerlendirilmesi:\n",
        "\n",
        "Optuna ile gerÃ§ekleÅŸtirilen 150 farklÄ± deneme sonucunda, validasyon seti Ã¼zerinde en yÃ¼ksek F1-Score (0.9863) deÄŸerine ulaÅŸan hiperparametre konfigÃ¼rasyonu ÅŸu ÅŸekilde belirlenmiÅŸtir:\n",
        "\n",
        "SÄ±ÄŸ Mimari Tercihi (n_layers: 1): Algoritma, Ã§ok katmanlÄ± (derin) yapÄ±lar yerine tek gizli katmanlÄ± yapÄ±yÄ± en baÅŸarÄ±lÄ± mimari olarak seÃ§miÅŸtir. Bu durum, veri setindeki Ã¶rÃ¼ntÃ¼lerin Ã§Ã¶zÃ¼lmesi iÃ§in karmaÅŸÄ±k derin aÄŸlara gerek olmadÄ±ÄŸÄ±nÄ±, daha sade bir modelin overfitting (ezberleme) riskinden kaÃ§Ä±narak daha iyi genelleme yaptÄ±ÄŸÄ±nÄ± gÃ¶stermektedir.\n",
        "\n",
        "Aktivasyon Fonksiyonu (logistic): Genellikle tercih edilen ReLU yerine Logistic (Sigmoid) fonksiyonunun seÃ§ilmesi dikkat Ã§ekicidir. Bu fonksiyon, tÃ¼revinin her noktada alÄ±nabilir olmasÄ± ve Ã¼rettiÄŸi yumuÅŸak (smooth) karar sÄ±nÄ±rlarÄ± sayesinde, bu veri setindeki kanser/saÄŸlÄ±klÄ± ayrÄ±mÄ±nda daha hassas Ã§alÄ±ÅŸmÄ±ÅŸtÄ±r.\n",
        "\n",
        "DÃ¼ÅŸÃ¼k Ã–ÄŸrenme HÄ±zÄ± (learning_rate: 0.00027): Optuna, standart (0.001) hÄ±z yerine daha dÃ¼ÅŸÃ¼k bir Ã¶ÄŸrenme oranÄ± seÃ§miÅŸtir. Bu, modelin sonuca \"koÅŸarak\" deÄŸil, \"kÃ¼Ã§Ã¼k ve emin adÄ±mlarla\" giderek global minimum noktasÄ±na daha hassas bir ÅŸekilde yerleÅŸtiÄŸini gÃ¶sterir.\n",
        "\n",
        "SonuÃ§: Optimize edilmiÅŸ bu model, manuel kurulan modellere kÄ±yasla veri setinin doÄŸasÄ±na (basit ama hassas) en uygun yapÄ±dadÄ±r."
      ],
      "metadata": {
        "id": "57nxAPh68zR8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.2 Optuna Arama AralÄ±klarÄ±** / ***9.3 EÄŸitim DÃ¶ngÃ¼sÃ¼***\n"
      ],
      "metadata": {
        "id": "2SkTqoFz98Kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 9.2 Optuna Arama AralÄ±klarÄ± ve Optimizasyon (DÃ¼zeltilmiÅŸ)\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "\n",
        "    # Katman YapÄ±sÄ±:  2 katmanlÄ± sabit yapÄ± kuruyoruz.\n",
        "    # Birinci katman 16-256 arasÄ±, Ä°kinci katman 8-128 arasÄ±.\n",
        "    l1 = trial.suggest_int('n_units_l1', 16, 256)\n",
        "    l2 = trial.suggest_int('n_units_l2', 8, 128)\n",
        "    hidden_layer_sizes = (l1, l2)\n",
        "\n",
        "    # Learning Rate (Log Uniform): 1e-5 ile 1e-1 arasÄ±\n",
        "    # Not: suggest_float(..., log=True) fonksiyonu loguniform ile aynÄ± iÅŸi yapar (gÃ¼ncel yÃ¶ntemdir)\n",
        "    learning_rate_init = trial.suggest_float('learning_rate_init', 1e-5, 1e-1, log=True)\n",
        "\n",
        "    # Alpha (Log Uniform): 1e-6 ile 1e-2 arasÄ±\n",
        "    alpha = trial.suggest_float('alpha', 1e-6, 1e-2, log=True)\n",
        "\n",
        "    # Activation: Sadece relu ve tanh\n",
        "    activation = trial.suggest_categorical('activation', [\"relu\", \"tanh\"])\n",
        "\n",
        "    # Solver (Ã‡Ã¶zÃ¼cÃ¼): adam veya sgd\n",
        "    solver = trial.suggest_categorical('solver', [\"adam\", \"sgd\"])\n",
        "\n",
        "    # Batch Size: 16, 32, 64, 128\n",
        "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
        "\n",
        "    # --- 2. MODEL KURULUMU ---\n",
        "    model = MLPClassifier(\n",
        "        hidden_layer_sizes=hidden_layer_sizes,\n",
        "        activation=activation,\n",
        "        solver=solver,\n",
        "        learning_rate_init=learning_rate_init,\n",
        "        alpha=alpha,\n",
        "        batch_size=batch_size,\n",
        "        random_state=42,\n",
        "        max_iter=500  # SGD bazen yavaÅŸ yakÄ±nsar, iterasyonu yÃ¼ksek tutmak iyidir\n",
        "    )\n",
        "\n",
        "    # --- 3. EÄÄ°TÄ°M VE TEST ---\n",
        "    # SGD kullanÄ±nca bazen 'convergence warning' verir, onu yakalamak yerine susturabiliriz\n",
        "    # ama ÅŸimdilik doÄŸal akÄ±ÅŸÄ±na bÄ±rakalÄ±m.\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Hedef: F1 Score\n",
        "    return f1_score(y_val, y_pred)\n",
        "\n",
        "# --- 4. OPTÄ°MÄ°ZASYONU BAÅLAT ---\n",
        "print(\"Verilen Kurallara GÃ¶re Optuna Optimizasyonu BaÅŸlÄ±yor (150 Deneme)...\")\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=150)\n",
        "\n",
        "print(\"-\" * 40)\n",
        "print(f\"ğŸ† Yeni En Ä°yi Skor (F1-Score): {study.best_trial.value:.4f}\")\n",
        "print(\"ğŸ” En Ä°yi Parametreler:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"    {key}: {value}\")"
      ],
      "metadata": {
        "id": "5wF2TG9V8zI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Belirlenen arama uzayÄ± (2 Gizli Katman zorunluluÄŸu) iÃ§erisinde gerÃ§ekleÅŸtirilen 150 deneme sonucunda, validasyon seti Ã¼zerinde en yÃ¼ksek F1-Score (0.9863) deÄŸerine ulaÅŸan final modelin parametreleri ÅŸu ÅŸekilde belirlenmiÅŸtir:\n",
        "\n",
        "GÃ¼Ã§lÃ¼ Mimari (107 ve 102 NÃ¶ron): Optuna, her iki katmanda da 100 civarÄ± nÃ¶ron kullanarak oldukÃ§a geniÅŸ kapasiteli bir aÄŸ Ã¶nermiÅŸtir.\n",
        "\n",
        "1. Katman: 107 NÃ¶ron\n",
        "\n",
        "2. Katman: 102 NÃ¶ron\n",
        "\n",
        " Bu yapÄ±, modelin veri setindeki karmaÅŸÄ±k detaylarÄ± yakalamak iÃ§in geniÅŸ bir \"beyin kapasitesine\" ihtiyaÃ§ duyduÄŸunu gÃ¶stermektedir.\n",
        "\n",
        "Ã–ÄŸrenme Parametreleri:\n",
        "\n",
        "Aktivasyon: ReLU seÃ§ilmiÅŸtir. Modern derin Ã¶ÄŸrenme modellerinde en sÄ±k kullanÄ±lan bu fonksiyon, iÅŸlemleri hÄ±zlandÄ±rmasÄ± ve \"Gradient Vanishing\" (gradyan kaybolmasÄ±) sorununu engellemesi nedeniyle Optuna tarafÄ±ndan Tanh'a tercih edilmiÅŸtir. Manuel denemelerde tanh aktivasyonu baÅŸarÄ±lÄ± gÃ¶rÃ¼nse de, Optuna ile yapÄ±lan kapsamlÄ± taramada ReLU fonksiyonunun doÄŸru nÃ¶ron sayÄ±sÄ± ve optimizasyon algoritmasÄ±yla (Adam) desteklendiÄŸinde daha Ã¼stÃ¼n performans gÃ¶sterdiÄŸi kanÄ±tlanmÄ±ÅŸtÄ±r.\n",
        "\n",
        "Solver: Adam seÃ§ilmiÅŸtir. Adaptif Ã¶ÄŸrenme hÄ±zÄ± sunan Adam algoritmasÄ±, SGD'ye gÃ¶re daha hÄ±zlÄ± ve kararlÄ± bir yakÄ±nsama saÄŸlamÄ±ÅŸtÄ±r.\n",
        "\n",
        "Batch Size: 16 gibi kÃ¼Ã§Ã¼k bir deÄŸer seÃ§ilmiÅŸtir. Bu, modelin aÄŸÄ±rlÄ±klarÄ±nÄ± daha sÄ±k gÃ¼ncellediÄŸini (her 16 Ã¶rnekte bir) ve bu sayede yerel minimumlardan daha kolay kurtularak en iyi sonucu bulduÄŸunu gÃ¶sterir.\n",
        "\n",
        "SonuÃ§: Optimize edilen bu model, geniÅŸ nÃ¶ron yapÄ±sÄ± ve sÄ±k gÃ¼ncellemeli (kÃ¼Ã§Ã¼k batch size) Ã¶ÄŸrenme stratejisiyle, veri setini neredeyse kusursuz Ã¶ÄŸrenmiÅŸtir.Optuna, sadece parametreleri sayÄ±sal olarak iyileÅŸtirmemiÅŸ; aynÄ± zamanda \"YavaÅŸ ve Dengeli\" Ã¶ÄŸrenme stratejisi yerine \"HÄ±zlÄ±, SÄ±k GÃ¼ncellemeli ve GeniÅŸ Kapasiteli\" bir stratejinin bu veri seti iÃ§in daha uygun olduÄŸunu kanÄ±tlamÄ±ÅŸtÄ±r."
      ],
      "metadata": {
        "id": "OR7wIGRaAg1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BÃ¶lÃ¼m 9.3: EÄŸitim DÃ¶ngÃ¼sÃ¼ ve AmaÃ§ Fonksiyonu (Objective Function)\n",
        "Optuna optimizasyon sÃ¼recinin Ã§ekirdeÄŸini oluÅŸturan objective fonksiyonu, her bir deneme (trial) iÃ§in ÅŸu adÄ±mlarÄ± otomatik olarak gerÃ§ekleÅŸtirmiÅŸtir:\n",
        "\n",
        "Model Kurulumu: Fonksiyon her Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda, Optuna'nÄ±n o anki deneme iÃ§in Ã¶nerdiÄŸi hiperparametreleri (Katman sayÄ±sÄ±, Learning Rate, Alpha vb.) alÄ±r ve bu parametrelerle yeni bir MLPClassifier modeli inÅŸa eder.\n",
        "\n",
        "EÄŸitim (Fitting): OluÅŸturulan bu model, X_train veri seti ile eÄŸitilir.\n",
        "\n",
        "DeÄŸerlendirme: EÄŸitilen model, X_val (DoÄŸrulama) seti Ã¼zerinde tahmin yapar.\n",
        "\n",
        "Geri Bildirim (Return Score): Tahmin sonuÃ§larÄ± ile gerÃ§ek deÄŸerler karÅŸÄ±laÅŸtÄ±rÄ±larak F1-Score hesaplanÄ±r ve bu skor Optuna'ya geri dÃ¶ndÃ¼rÃ¼lÃ¼r (return).\n",
        "\n",
        "Optuna, dÃ¶nen bu skora bakarak bir sonraki denemede hangi parametreleri seÃ§eceÄŸine karar verir ve bu dÃ¶ngÃ¼ 150 kez tekrarlanÄ±r."
      ],
      "metadata": {
        "id": "CS3Io5WJCuD3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9.4 En Ä°yi Trialâ€™Ä±n RaporlanmasÄ±**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_KG66v5IDD8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 9.4 En Ä°yi Trial'Ä±n RaporlanmasÄ±\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "# 1. En Ä°yi Parametreleri AlalÄ±m\n",
        "best_params = study.best_params\n",
        "\n",
        "print(f\"ğŸ† EN Ä°YÄ° HÄ°PERPARAMETRE SETÄ° (Trial #{study.best_trial.number}):\")\n",
        "print(\"-\" * 50)\n",
        "for k, v in best_params.items():\n",
        "    print(f\"{k:20} : {v}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 2. Bu parametrelerle Final Modeli KuralÄ±m\n",
        "# (Dikkat: Katman yapÄ±sÄ±nÄ± sÃ¶zlÃ¼kten tuple formatÄ±na Ã§eviriyoruz)\n",
        "final_hidden_layers = (best_params['n_units_l1'], best_params['n_units_l2'])\n",
        "\n",
        "optuna_model = MLPClassifier(\n",
        "    hidden_layer_sizes=final_hidden_layers,\n",
        "    activation=best_params['activation'],\n",
        "    solver=best_params['solver'],\n",
        "    learning_rate_init=best_params['learning_rate_init'],\n",
        "    alpha=best_params['alpha'],\n",
        "    batch_size=best_params['batch_size'],\n",
        "    random_state=42,\n",
        "    max_iter=500\n",
        ")\n",
        "\n",
        "# 3. Modeli EÄŸit (X_train ile)\n",
        "optuna_model.fit(X_train, y_train)\n",
        "\n",
        "# 4. Validasyon Seti ile TÃ¼m Metrikleri Hesapla\n",
        "y_pred_val = optuna_model.predict(X_val)\n",
        "y_proba_val = optuna_model.predict_proba(X_val)[:, 1]\n",
        "\n",
        "print(\"\\nğŸ“Š OPTÄ°MÄ°ZE EDÄ°LMÄ°Å MODELÄ°N VALIDATION SKORLARI:\")\n",
        "print(f\"Accuracy (DoÄŸruluk) : {accuracy_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"Precision (Kesinlik): {precision_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"Recall (DuyarlÄ±lÄ±k) : {recall_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"F1-Score            : {f1_score(y_val, y_pred_val):.4f}\")\n",
        "print(f\"ROC-AUC             : {roc_auc_score(y_val, y_proba_val):.4f}\")"
      ],
      "metadata": {
        "id": "MYqYQzpCCKKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optuna tarafÄ±ndan belirlenen en iyi hiperparametre seti kullanÄ±larak (Trial #4) final model oluÅŸturulmuÅŸ ve validasyon seti Ã¼zerinde test edilmiÅŸtir. Elde edilen sonuÃ§lar, modelin manuel kurulan modellere kÄ±yasla Ã¼stÃ¼nlÃ¼ÄŸÃ¼nÃ¼ kanÄ±tlamaktadÄ±r.\n",
        "\n",
        "1. Parametre Analizi:\n",
        "\n",
        "Mimari: 1. Katman (107 NÃ¶ron) ve 2. Katman (102 NÃ¶ron) ile geniÅŸ kapasiteli bir aÄŸ yapÄ±sÄ± seÃ§ilmiÅŸtir.\n",
        "\n",
        "Strateji: Learning Rate: 0.061 (YÃ¼ksek hÄ±z) ve Batch Size: 16 (SÄ±k gÃ¼ncelleme) kombinasyonu, modelin agresif ve hÄ±zlÄ± bir Ã¶ÄŸrenme sÃ¼reci geÃ§irdiÄŸini doÄŸrulamaktadÄ±r.\n",
        "\n",
        "Aktivasyon: ReLU ve Adam ikilisi ile modern ve hÄ±zlÄ± bir yapÄ± kurulmuÅŸtur.\n",
        "\n",
        "2. Performans Metrikleri:\n",
        "\n",
        "Accuracy (DoÄŸruluk): 0.9825 (Genel baÅŸarÄ± Ã§ok yÃ¼ksektir).\n",
        "\n",
        "Recall (DuyarlÄ±lÄ±k): 1.0000 (Kritik BaÅŸarÄ±!)\n",
        "\n",
        "Yorum: Model, validasyon setindeki tÃ¼m kanserli vakalarÄ± eksiksiz tespit etmiÅŸtir. YanlÄ±ÅŸ Negatif (False Negative) oranÄ±nÄ±n sÄ±fÄ±r olmasÄ±, bu modelin tÄ±bbi teÅŸhis iÃ§in gÃ¼venle kullanÄ±labileceÄŸini gÃ¶sterir.\n",
        "\n",
        "Precision (Kesinlik): 0.9730\n",
        "\n",
        "Yorum: Recall'un kusursuz olmasÄ±na raÄŸmen Precision'Ä±n bu kadar yÃ¼ksek kalmasÄ±, modelin \"herkese kanser diyerek\" deÄŸil, gerÃ§ekten Ã¶ÄŸrenerek bu baÅŸarÄ±yÄ± yakaladÄ±ÄŸÄ±nÄ±, yanlÄ±ÅŸ alarm oranÄ±nÄ±n Ã§ok dÃ¼ÅŸÃ¼k olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "F1-Score: 0.9863 (Optimizasyon hedefi maksimize edilmiÅŸtir).\n",
        "\n",
        "ROC-AUC: 0.9907 (AyrÄ±ÅŸtÄ±rma gÃ¼cÃ¼ mÃ¼kemmel seviyededir).\n",
        "\n",
        "SonuÃ§: Optuna optimizasyonu sonucunda elde edilen model, hem kanseri kaÃ§Ä±rmama (Recall: 1.0) hem de genel doÄŸruluk aÃ§Ä±sÄ±ndan manuel modellerden daha dengeli ve baÅŸarÄ±lÄ± bir profil Ã§izmiÅŸtir."
      ],
      "metadata": {
        "id": "ZlcDCWBEDmI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **10. XAI â€“ SHAP AÃ§Ä±klanabilirlik Analizi **"
      ],
      "metadata": {
        "id": "8_ocDM4lD6HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "# ... Model ve X_test'in tanÄ±mlÄ± olduÄŸu varsayÄ±lÄ±r ...\n",
        "\n",
        "# 1. Tahmin Fonksiyonunu TanÄ±mlama\n",
        "def f(X):\n",
        "    # MLPClassifier iÃ§in olasÄ±lÄ±k tahminlerini kullanÄ±n\n",
        "    return model.predict_proba(X)\n",
        "\n",
        "# 2. Explainer (AÃ§Ä±klayÄ±cÄ±) OluÅŸturma\n",
        "# Model yerine tahmin fonksiyonunu (f) kullanÄ±n\n",
        "explainer = shap.Explainer(f, X_test)\n",
        "\n",
        "# 3. SHAP deÄŸerlerini hesaplama ve deÄŸiÅŸkene atama\n",
        "# MLPClassifier Ã§Ä±ktÄ±sÄ± 2 boyutlu olduÄŸu iÃ§in shap_values, bir liste yerine tek bir ShapValues nesnesi dÃ¶ndÃ¼rÃ¼r.\n",
        "# Ancak bazen (Ã¶zellikle Ã§ok sÄ±nÄ±flÄ± modellerde) liste dÃ¶nebilir, bu durumda shap_values[1] veya [0] kullanmanÄ±z gerekebilir.\n",
        "shap_values = explainer(X_test)\n",
        "\n",
        "# --- Geri kalan kontrol kodunuz ---\n",
        "print(\"=== BOYUT KONTROLÃœ ===\")\n",
        "print(\"X_test shape:\", np.array(X_test).shape)\n",
        "\n",
        "# ... DiÄŸer kontrol print satÄ±rlarÄ±nÄ±z ..."
      ],
      "metadata": {
        "id": "jYrssH4PDrBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 10. XAI - SHAP BÄ°RLEÅTÄ°RÄ°LMÄ°Å ANALÄ°Z VE GÃ–RSELLEÅTÄ°RME\n",
        "# ---------------------------------------------------------\n",
        "\n",
        "print(\"SHAP Analizi BAÅTAN SONA BAÅLATILIYOR...\")\n",
        "\n",
        "# 1. SHAP DEÄERLERÄ°NÄ° TEMÄ°ZDEN HESAPLAMA\n",
        "X_train_summary = shap.kmeans(X_train, 50)\n",
        "explainer = shap.KernelExplainer(optuna_model.predict_proba, X_train_summary)\n",
        "shap_values = explainer.shap_values(X_test, nsamples=100)\n",
        "\n",
        "# 2. SHAP FORMATINI DÃœZELTME (3D â†’ 2D)\n",
        "# shap_values boyutu: (114, 30, 2)\n",
        "# Pozitif sÄ±nÄ±f (1) SHAP deÄŸerlerini alÄ±yoruz\n",
        "shap_vals_cancer = shap_values[:, :, 1]\n",
        "\n",
        "# Base value (pozitif sÄ±nÄ±f iÃ§in)\n",
        "base_value = explainer.expected_value[1]\n",
        "\n",
        "# Plot Ã§izimleri iÃ§in temiz DataFrame\n",
        "X_plot_df = pd.DataFrame(X_test, columns=data.feature_names)\n",
        "\n",
        "# Force/Decision Plot iÃ§in Ã¶rnek index\n",
        "hasta_no = 0\n",
        "\n",
        "print(\"\\nSHAP DeÄŸerleri HesaplandÄ±. 4 Grafik Ã‡iziliyor...\")\n",
        "\n",
        "# --- GRAFÄ°K 1: SUMMARY PLOT (DOTS) ---\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_vals_cancer, X_plot_df, show=False)\n",
        "plt.title(\"Summary Plot: Ã–zelliklerin Karara Etki YÃ¶nÃ¼ (Kanser SÄ±nÄ±fÄ±)\", fontsize=12, y=1.05)\n",
        "plt.subplots_adjust(top=0.9, bottom=0.1)\n",
        "plt.show()\n",
        "\n",
        "# --- GRAFÄ°K 2: BAR PLOT (Ortalama Etki BÃ¼yÃ¼klÃ¼kleri) ---\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.summary_plot(shap_vals_cancer, X_plot_df, plot_type=\"bar\", show=False)\n",
        "plt.title(\"Bar Plot: Ã–zelliklerin Ortalama Mutlak Etki BÃ¼yÃ¼klÃ¼ÄŸÃ¼\", fontsize=12, y=1.05)\n",
        "plt.subplots_adjust(top=0.9, bottom=0.1)\n",
        "plt.show()\n",
        "\n",
        "# --- GRAFÄ°K 3: FORCE PLOT (Tek Hasta Ä°Ã§in) ---\n",
        "print(f\"\\n--- Hasta #{hasta_no} Ä°Ã§in Force Plot Analizi ---\")\n",
        "shap.force_plot(\n",
        "    base_value,\n",
        "    shap_vals_cancer[hasta_no],\n",
        "    X_plot_df.iloc[hasta_no],\n",
        "    matplotlib=True\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# --- GRAFÄ°K 4: DECISION PLOT ---\n",
        "print(f\"\\n--- Hasta #{hasta_no} Ä°Ã§in Decision Plot Analizi ---\")\n",
        "plt.figure(figsize=(10, 8))\n",
        "shap.decision_plot(\n",
        "    base_value,\n",
        "    shap_vals_cancer[hasta_no],\n",
        "    X_plot_df.iloc[hasta_no],\n",
        "    show=False\n",
        ")\n",
        "plt.title(f\"Decision Plot: Hasta #{hasta_no} Karar Yolu\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nSHAP Analizi BaÅŸarÄ±yla TamamlandÄ±! ğŸ‰\")\n"
      ],
      "metadata": {
        "id": "2YHcECBuQwRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10.2 Optuna En Ä°yi Model iÃ§in SHAP Analizi**"
      ],
      "metadata": {
        "id": "sJvUoKKDH_Jo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimize edilen modelin karar mekanizmasÄ±, SHAP (SHapley Additive exPlanations) yÃ¶ntemiyle detaylÄ±ca incelenmiÅŸtir. Bu analiz, modelin sadece yÃ¼ksek skorlar vermekle kalmayÄ±p, bu kararlarÄ± tÄ±bbi gerÃ§eklerle uyumlu bir ÅŸekilde verdiÄŸini kanÄ±tlamaktadÄ±r.\n",
        "\n",
        "1. Grafikler Ãœzerinden Bulgular\n",
        "A. BaskÄ±n Ã–zellikler (Bar Plot Analizi)\n",
        "Grafik: incelendiÄŸinde, modelin kararÄ±na ortalama olarak en Ã§ok katkÄ± saÄŸlayan ilk Ã¼Ã§ Ã¶zellik ÅŸunlardÄ±r:\n",
        "\n",
        "mean concavity (Ortalama Ä°Ã§bÃ¼keylik)\n",
        "\n",
        "worst concave points (En KÃ¶tÃ¼ Ä°Ã§bÃ¼key Noktalar)\n",
        "\n",
        "worst area (En KÃ¶tÃ¼ Alan)\n",
        "\n",
        "Yorum: Model, hÃ¼crenin boyutuna (worst area) deÄŸil, ÅŸekil bozukluÄŸuna (concavity, concave points) daha fazla aÄŸÄ±rlÄ±k vermektedir. Bu, hÃ¼crenin dÃ¼zgÃ¼nlÃ¼ÄŸÃ¼nÃ¼n veya kenar yapÄ±sÄ±nÄ±n kanser teÅŸhisinde en kritik biyomarker olduÄŸunu gÃ¶sterir.\n",
        "\n",
        "B. Etki YÃ¶nÃ¼ Analizi (Summary Plot Analizi)\n",
        "Grafik: incelendiÄŸinde:\n",
        "\n",
        "Kanser Riski: Listede Ã¼st sÄ±ralarda yer alan Ã¶zelliklerin (mean concavity, worst concave points) deÄŸerleri yÃ¼kseldikÃ§e (kÄ±rmÄ±zÄ± noktalar), SHAP deÄŸerleri sola doÄŸru (negatife) kaymaktadÄ±r. (Biz Kanser SÄ±nÄ±fÄ± 0'Ä± analiz ettiÄŸimiz iÃ§in, negatif SHAP deÄŸeri = Kanser riskini azaltÄ±yor [Temiz] anlamÄ±na gelir; pozitif SHAP deÄŸeri = Kanser riskini artÄ±rÄ±yor [Kanser] anlamÄ±na gelir.) Bu durumda: YÃ¼ksek Alan/Ä°Ã§bÃ¼keylik (KÄ±rmÄ±zÄ±) pozitif SHAP deÄŸeri Ã¼retip modelin Kanser kararÄ±na destek vermektedir.\n",
        "\n",
        "TutarlÄ±lÄ±k: Model, hÃ¼crenin iÃ§bÃ¼keyliÄŸi ve alanÄ±nÄ±n anormal derecede bÃ¼yÃ¼k olmasÄ±nÄ± doÄŸrudan kanser riskini artÄ±ran (pozitif SHAP) faktÃ¶rler olarak gÃ¶rmÃ¼ÅŸtÃ¼r."
      ],
      "metadata": {
        "id": "HN-MQf3rHkt6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Madde,Analiz Sonucu\n",
        "Hangi Ã¶zellikler kararlarÄ± belirledi?: mean concavity ve worst concave points gibi ÅŸekil bozukluÄŸu belirten Ã¶zellikler, mutlak bÃ¼yÃ¼klÃ¼k (Ã¶rn. mean radius) belirten Ã¶zelliklerden daha baskÄ±ndÄ±r.\n",
        "\n",
        "Optunaâ€™nÄ±n bulduÄŸu model hangi Ã¶zelliklere daha duyarlÄ±?: Model, karar verirken mean concavity ve worst concave points deÄŸerlerindeki deÄŸiÅŸimlere karÅŸÄ± en yÃ¼ksek duyarlÄ±lÄ±ÄŸÄ± gÃ¶sterir (Bar Plot'taki en uzun Ã§ubuklar).\n",
        "\n",
        "MLP modellerindeki ortak ve farklÄ± SHAP paternleri neler?: Patern: Force Plot ve Decision Plot incelendiÄŸinde, kararÄ±n lineer (dÃ¼z) bir Ã§izgi halinde deÄŸil, Ã¶zellik etkileÅŸimlerine baÄŸlÄ± olarak zikzaklar Ã§izerek oluÅŸtuÄŸu gÃ¶rÃ¼lÃ¼r. Bu, MLP'nin doÄŸrusal olmayan (non-linear) bir yaklaÅŸÄ±mla, Ã¶zelliklerin birbirini nasÄ±l etkilediÄŸini Ã¶ÄŸrenerek kararlar verdiÄŸini kanÄ±tlar."
      ],
      "metadata": {
        "id": "IQmP_nDDjPBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Tek HastalÄ±k Karar Yolu (Force Plot Analizi)\n",
        "Grafik: incelenen Ã¶rnek hastada, modelin ortalama tahmin deÄŸeri (base value) 0.60 civarÄ±ndadÄ±r.\n",
        "\n",
        "Model, worst perimeter gibi Ã¶zelliklerin yÃ¼ksek deÄŸerleri nedeniyle kararÄ± agresif bir ÅŸekilde sola (dÃ¼ÅŸÃ¼k f(x) deÄŸeri, yani Malignant/Kanser) doÄŸru itmiÅŸtir. HastanÄ±n nihai sonucu (f(x)=0.00) bu itme kuvvetlerinin baskÄ±n geldiÄŸini ve modelin bu hastayÄ± yÃ¼ksek kesinlikle kanser olarak teÅŸhis ettiÄŸini gÃ¶stermektedir.\n",
        "\n",
        "Not: Force Plot'taki aÅŸÄ±rÄ± uzun sayÄ±lar, yuvarlama iÅŸlemi yapÄ±lsa bile SHAP'in static Ã§iziminde zaman zaman yaÅŸanan format sorunudur, ancak raporun analizi iÃ§in grafiÄŸin yÃ¶nÃ¼ ve renkleri yeterlidir."
      ],
      "metadata": {
        "id": "w5LacsyrjUni"
      }
    }
  ]
}